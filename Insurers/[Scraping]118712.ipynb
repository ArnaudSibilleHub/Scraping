{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages import\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requests url and content\n",
    "req = rq.get('https://www.118712.fr/annuaire/ville/roubaix-59/assurance-professionnelle')\n",
    "page_content = req.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "bs_content = BeautifulSoup(page_content, 'html.parser')\n",
    "bs_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dynamic content -> Selenium\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "#submodules and classes within selenium.webdriver.common\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "#manage exceptions tracking with common classes\n",
    "from selenium.common.exceptions import NoSuchWindowException , TimeoutException, WebDriverException, NoSuchElementException\n",
    "\n",
    "#set up chrome webdriver classes\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "#set up Webdriverwait and support classes\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#request\n",
    "try:\n",
    "    #Initialize Webdriver\n",
    "    service = Service()\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.get('https://www.118712.fr/recherche/auto/roubaix/assurance-professionnelle')\n",
    "\n",
    "     \n",
    "\n",
    "    #click PrivacyCompliance\n",
    "    # button_Ok = driver.find_element(By.CSS_SELECTOR, '#privacy-cookie-banner__privacy-accept')\n",
    "    # button_Ok.click()\n",
    "\n",
    "    #find and count 'next page buttons' to define how many pages are to scrap\n",
    "    buttons = driver.find_elements(By.CSS_SELECTOR, 'button.len1.adpJam')\n",
    "    nbPage = 0\n",
    "\n",
    "    #loop in buttons list to check if onclick attrbutes match with 'next buttons'\n",
    "    for button in buttons:\n",
    "        onclick_attribute = button.get_attribute('onclick')\n",
    "        if onclick_attribute:\n",
    "            pattern=r'changePageUseCurrentBounds\\(\\d+\\)'\n",
    "            match = re.search(pattern, onclick_attribute)\n",
    "            # sum nb of pages\n",
    "            if match:\n",
    "                nbPage +=1\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "     #create empty lists in wich append informations as names(titles) and street address\n",
    "    titles_all=[]\n",
    "    addresses_all = []\n",
    "    cities_all = []\n",
    "\n",
    "    #loop through page results \n",
    "\n",
    "    for page in range(1,(nbPage+2)*2):\n",
    "\n",
    "        # Wait for the elements to be visible\n",
    "        elements_loaded = WebDriverWait(driver, 20).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, 'h2.h4')))\n",
    "       # Fetch and print the text of the elements\n",
    "        titles = [h2Elt.text   for h2Elt in elements_loaded]\n",
    "        #print(titles)\n",
    "        titles_all.append(titles)\n",
    "\n",
    "        # Fetch and print the text of the address\n",
    "        elements_addresses = driver.find_elements(By.CSS_SELECTOR, 'article > address.bi_adress.txt_md > p:first-child' )\n",
    "\n",
    "        addresses = [address.text for address in elements_addresses]\n",
    "        addresses_all.append(addresses)\n",
    "\n",
    "        elements_cities = driver.find_elements(By.CSS_SELECTOR, 'article > address.bi_adress.txt_md > p:nth-child(2)' )\n",
    "        cities = [citie.text for citie in elements_cities]\n",
    "        cities_all.append(cities)\n",
    "        \n",
    "    #find phone numbers, displayed after clicking a first button\n",
    "        #locate buttons 'fantomas' to click\n",
    "        buttons_tobeclicked_located = driver.find_elements(By.CSS_SELECTOR, 'section.bi_list > article.bi.adp-map-item  > div.bi_cta > a.button.primary.bi_fantomas')\n",
    "        \n",
    "    #create an ampty list to add list numbers\n",
    "\n",
    "        tel_nb_list = []\n",
    "        for button in buttons_tobeclicked_located:\n",
    "        \n",
    "        # Move to the button before clicking with 'ActionChains' webdriver submodule ans classes\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(button).perform()\n",
    "            #click button to display phone numbe\n",
    "            button.click()\n",
    "            # driver.implicitly_wait(2)\n",
    "    \n",
    "            #wait display and locate buttons mentionin tel number, dispayed after clicking initial button\n",
    "            button_tel_located = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'section.bi_list > article.bi.adp-map-item > div.bi_cta > a.button.primary.ab_test')))\n",
    "\n",
    "            #collect list of \"a\" html elt      \n",
    "            links = driver.find_elements(By.CSS_SELECTOR, 'a.button.primary.ab_test')\n",
    "\n",
    "            #loop in buttons list to extract href attribute containing tel number\n",
    "            for link in links: \n",
    "                tel_href = link.get_attribute('href')\n",
    "                tel_nb_list.append(tel_href)\n",
    "\n",
    "# click 'next button' by HTML id attribute ()\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, 'button.len1.adpJam')\n",
    "        next_button.click()\n",
    "\n",
    "        # Optional: Add a delay to ensure the page fully loads before extracting results\n",
    "        # time.sleep(2)\n",
    "\n",
    "#manage alle possible exceptiosn\n",
    "except NoSuchWindowException as NsWe:\n",
    "    print(f\"exception handled: {NsWe}\")\n",
    "except TimeoutException as te:\n",
    "    print(f\"TimeoutException: {te}\")\n",
    "    # Handle timeout exception\n",
    "except WebDriverException as wde:\n",
    "    print(f\"WebDriverException: {wde}\")\n",
    "    # Handle WebDriver related exception\n",
    "except NoSuchElementException as nse:\n",
    "    print(f\"NoSuchElementException: {nse}\")\n",
    "    # Handle NoSuchElementException\n",
    "except Exception as ex:\n",
    "    print(f\"An unexpected exception occurred: {ex}\")\n",
    "    # Handle other exceptions\n",
    "\n",
    "#close driver\n",
    "finally:\n",
    "    # Close the browser window in the finally block to ensure it's closed even if an exception occurs\n",
    "    if 'driver' in locals() and driver is not None:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want a flat list containing titles from all pages, use extend\n",
    "flat_titles_list = [title for titles_page in titles_all for title in titles_page]\n",
    "print(flat_titles_list) \n",
    "flat_addresses_list = [address for addresses_page in addresses_all for address in addresses_page]\n",
    "print(flat_addresses_list)  \n",
    "flat_cities_list = [citie for cities_page in cities_all for citie in cities_page]\n",
    "print(flat_cities_list)  \n",
    "print(tel_nb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the number of rows and only use the half because iteratio on the double of page number + flip rows because seems to be better fitted on the second half\n",
    "max_rows = (len(flat_titles_list)) \n",
    "flat_titles_list = np.array(flat_titles_list)[::-1]\n",
    "flat_titles_list = flat_titles_list[:max_rows]\n",
    "flat_addresses_list = np.array(flat_addresses_list)[::-1]\n",
    "flat_addresses_list = flat_addresses_list[:max_rows]\n",
    "flat_cities_list = np.array(flat_cities_list)[::-1]\n",
    "flat_cities_list = flat_cities_list[:max_rows]\n",
    "tel_nb_list = np.array(tel_nb_list)[::-1]\n",
    "tel_nb_list = tel_nb_list[:max_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurers_list2 = {'insurers': flat_titles_list,\n",
    "                 'address' : flat_addresses_list,\n",
    "                 'city': flat_cities_list,\n",
    "                 'tel': tel_nb_list}\n",
    "    \n",
    "insurers_list2 = pd.DataFrame.from_dict(insurers_list2)\n",
    "insurers_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insurers_list2[['zip_code', 'city']] = insurers_list2['city'].str.split(' ', n=1, expand=True)\n",
    "# insurers_list2\n",
    "# Split the 'city' column into 'zip code' and 'city' columns\n",
    "# insurers_list2[['zip code', 'city']] = pd.DataFrame(insurers_list2['city'].assign(lambda x: x.str.split(' ', n=1, expand=True)))\n",
    "insurers_list2[['zip code', 'city']] = insurers_list2['city'].str.split(n=1, expand=True)\n",
    "# Display the updated DataFrame\n",
    "print(insurers_list2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurers_list2_cities_mask = [\"Lille\", \"Lambersart\", \"Villeneuve D'Ascq\", \"Wasquehal\", \"Roubaix\"]\n",
    "mask = insurers_list2['city'].isin(insurers_list2_cities_mask )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurers_list2_f = insurers_list2.loc[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "insurers_list2_f.to_csv('leads_insurers_RbxAndCo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAND BOX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming insurers_list2 is a dictionary-like object\n",
    "# Convert it to a DataFrame\n",
    "insurers_list2_df = pd.DataFrame.from_dict(insurers_list2)\n",
    "\n",
    "# Group the DataFrame by the 'city' column and apply the all() function\n",
    "insurers_list2_grouped = insurers_list2_df.groupby('city').tail()\n",
    "\n",
    "# Print or use the resulting DataFrame\n",
    "print(insurers_list2_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming insurers_list2 is a DataFrame\n",
    "\n",
    "# Create a boolean mask based on whether the 'city' column ends with 'Roubaix'\n",
    "mask = insurers_list2['city'].str.endswith('baix')\n",
    "\n",
    "# Filter the DataFrame using boolean indexing\n",
    "filtered_insurers_list2 = insurers_list2[mask]\n",
    "\n",
    "# Print or use the filtered DataFrame\n",
    "print(filtered_insurers_list2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurers_list2_noDup_f = insurers_list2.drop_duplicates(keep='last')\n",
    "insurers_list2_noDup_f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
